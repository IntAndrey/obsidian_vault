---
title: "Claude Code теперь можно запускать с локальными open-source моделями"
source: "https://habr.com/ru/news/986124/"
author:
  - "[[Developer Hero]]"
published: 2026-01-17
created: 2026-01-18
description: "Начиная с версии Ollama 0.14, платформа получила совместимость с Anthropic Messages API. Это означает, что Claude Code — агентный инструмент для программирования, который работает прямо в терминале —..."
tags:
  - "clippings"
---
Начиная с версии Ollama 0.14, платформа [получила](https://ollama.com/blog/claude) совместимость с Anthropic Messages API. Это означает, что Claude Code — агентный инструмент для программирования, который работает прямо в терминале — теперь может использовать **любую модель из Ollama**, а не только облачные модели Anthropic.

![](https://habrastorage.org/r/w780/getpro/habr/upload_files/66e/d77/54d/66ed7754deb579662bd8bedd5ad62c71.png)

По сути, Claude Code думает, что общается с Anthropic API, но на самом деле запросы уходят в локально запущенную модель. Достаточно указать Ollama как base URL — и инструмент начинает работать с open-source LLM так же, как раньше с Claude.

Claude Code умеет читать и писать код, анализировать проекты, работать с файлами и вызывать инструменты. Раньше для этого требовался доступ к облаку, теперь — достаточно локальной модели с большим контекстом.

Поддерживаются как локальные модели (например, gpt-oss:20b или qwen-coder), так и облачные модели из Ollama Cloud. Рекомендуется использовать модели с контекстом от 64k токенов — иначе агент быстро упрётся в лимиты.

![](https://habrastorage.org/r/w780/getpro/habr/upload_files/c0a/d48/aac/c0ad48aacfcacd4652bc82f2ccf9243b.png)

Важно, что совместимость работает не только в CLI. Любые приложения, которые уже используют Anthropic SDK, можно переключить на Ollama, просто сменив base URL. Python, JavaScript, streaming, tool calling, system prompts — всё это поддерживается без изменений кода.

Фактически Ollama становится универсальным «прокси-Anthropic API» для open-source моделей. А Claude Code — первым популярным агентным инструментом, который можно полноценно запускать локально, без отправки кода в облако.

## Русскоязычное сообщество про AI в разработке

![](https://habrastorage.org/r/w780/getpro/habr/upload_files/d06/6a8/148/d066a81482f4fe77b245ab293d3beffc.png)

Друзья! Эту новость подготовила команда ТГК « [AI for Devs](https://t.me/+JUqqj8QsuRFlNGEy) » — канала, где мы рассказываем про AI-ассистентов, плагины для IDE, делимся практическими кейсами и свежими новостями из мира ИИ. [Подписывайтесь](https://t.me/+JUqqj8QsuRFlNGEy), чтобы быть в курсе и ничего не упустить!

+5

Через 3, 2, 1...

Как меняется работа в data

Работать без психологических проблем

Годнота из блогов компаний

Когнитивные искажения